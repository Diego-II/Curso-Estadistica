%!TEX root = apunte_estadistica.tex


\chapter{Más Sobre Estimadores}

\section{Intervalos de Confianza} 

En muchas aplicaciones, no es suficiente reportar una estimación puntual, es decir, un valor único para le parámetro a estimar, sino que debe identificarse una rango donde, con cierta probabilidad, el parámetro real está contenido. Esto motiva la siguiente definición: 

\begin{definition}[Intervalo de confianza]
\label{def:conf_inter} Un $(1-\alpha)$-intervalo de confianza para el parámetro $\theta$, $\alpha\in[0,1]$, es el intervalo aleatorio $(A(X),B(X))$ tal que 
\begin{equation}
	\label{eq:conf_inter}
	\Probt{A(X)\leq\theta\leq B(X)} = 1-\alpha, \forall \theta\in\Theta.
\end{equation}
\end{definition}

\begin{remark}
	Es importante notara que la definición arriba no es un enunciado de probabilidad en $\theta$, o en otras palabras, no describe una probabilidad sobre el parámetro $\theta$; pues recordemos que éste es fijo. Por el contrario, lo que es aleatorio en la ecuación \eqref{eq:conf_inter} es el intervalo, no el parámetros. Entonces, si bien es una sutileza, la definición anterior se debe entender como la probabilidad de que ``el intervalo (aleatorio) contenga al parámetro (fijo)'', y no como la probabilidad de que `el parámetro esté en el intervalo'. 
\end{remark}
Una consecuencia clave de este concepto es que si $I_{1-\alpha}$ es un $(1-\alpha)$-intervalo de confianza, entonces si fuese posible repetir una gran cantidad de veces el ejercicio de recolectar datos $X$ y calcular este intervalo para cada una de estas observaciones, entonces el parámetro $\theta$ estaría contenido en le intervalo un $(1-\alpha)\%$. Esto es muy diferente de asegurar que para un solo experimento, la probabilidad de que el parámetro $\theta$ esté contenido en $I_{1-\alpha}$ es $1-\alpha$, lo cual no es cierto. Los siguientes ejemplos tienen por objetivo ayudar a aclarar este concepto.

\begin{example}[Intervalo de confianza para la media de la distribución normal]
	Consideremos la muestra $X_1,\ldots,X_\nu\sim\cN(\theta,1)$. Como $\bar{X}=\frac{1}{n}\sum_{i=1}^nX_i\sim\cN(\theta,1/n)$ tenemos que  
	\begin{equation}
			\sqrt{n}(\bar{X}-\theta)\sim\cN(0,1).
		\end{equation}	
	Esta cantidad se llama \emph{pivote} y es una función (de la VA y del parámetro) cuya distribución no depende del parámetro. Consecuentemente, podemos identificar directamente un intervalo de confianza para el pivote desde una tabla de valores para la distribución normal de media cero y varianza unitaria. Si $\phi(x)$ denota la distribución Normal, entonces podemos elegir  $x_1$ y $x_2$ tal que $\phi(x_2)-\phi(x_1) = 1-\alpha$ con lo que tenemos
	\begin{equation}
	 	\Probt{x_1 \leq \sqrt{n}(\theta-\bar{X}) \leq x_2} = 1-\alpha \Leftrightarrow \Probt{\bar{X} + x_1/\sqrt{n} \leq \theta \leq \bar{X} + x_2/\sqrt{n}} = 1-\alpha,
	 \end{equation} 
	 es. decir, $(\bar{X} + x_1/\sqrt{n},\bar{X} + x_2/\sqrt{n})$ es el $(1-\alpha)$-intervalo de confianza de $\theta$. Eligiendo $\alpha=0.05$ tenemos $x_2 = -x_1 =1.96$ con lo que el intervalo de confianza del 95\% para $\theta$ está dado por 
	 \begin{equation}
	 	(\bar{X} -1.96/\sqrt{n},\bar{X} + 1.96/\sqrt{n}).
	 \end{equation}

	 El procedimiento estándar para encontrar intervalos de confianza es como el ilustrado en el ejemplo anterior, en donde construimos una cantidad que tiene una distribución que no depende del parámetro desconocido (llamada pivote). Construir un intervalo de confianza para esta cantidad es directo desde las tablas de distribuciones, luego, podemos encontrar el intervalo de confianza para la cantidad deseada, e.g., el parámetro desconocido, mediante transformaciones de la expresión del pivote. 

	 \begin{remark}
	 	El intervalo de confianza no es único. Por ejemplo, en el caso gaussiano podemos elegir en intervalo centrado en cero o desde $-\infty$. Esta elección dependerá de las aplicación en cuestión: una regla general es elegirlo de forma centrada para densidades que son simétricas, centrado en la moda para distribuciones unimodales, mientas que para densidades con soporte positivo podemos elegirlo desde cero. 
	 \end{remark}

	 Hasta ahora hemos solo definido intervalos de confianza para cantidades escalares, en donde el concepto de intervalo tiene sentido. Para parámetros vectoriales, nos referiremos a  \textit{conjuntos de confianza}. Siguiendo la Definición \ref{def:conf_inter}, un $(1-\alpha)$-conjunto de confianza $S(X)$ es tal que 
	 \begin{equation}
	\label{eq:conf_set}
	\Probt{\theta\in S(X)} = 1-\alpha, \forall \theta\in\Theta.
\end{equation}
\end{example}


\begin{exercise}
Considere $X_1,\ldots,X_{50}\sim\cN(0,\sigma^2)$, calcule el intervalo de confianza del 99\%.
\end{exercise}

\begin{example}[Intervalo de confianza para Bernoulli] Consideremos $X_1,\ldots,X_{n}\sim\ber{\theta}$ y calculemos un intervalo de confianza para $\theta$. Recordemos que el EMV es $\thetahat = \frac{1}{n}\sum_{i=1}^nX_i$ y debido a la normalidad asintótica del EMV, tenemos que para $n$ grande, podemos asumir 
\begin{equation}
	\thetahat\sim\cN\left(\theta,\frac{\theta(1-\theta)}{n}\right)
\end{equation}
donde la varianza $\frac{\theta(1-\theta)}{n}=I_n(\theta)^{-1}$ es la inversa de la información de Fisher. 

Podemos entonces considerar el pivote
\begin{equation}
	\frac{\sqrt{n}(\thetahat-\theta)}{\sqrt{\theta(1-\theta)}}\sim\cN(0,1)
\end{equation}
y calcular el $(1-\alpha)$-intervalo de confianza asumiendo los valores $x_1$ y $x_2$ mediante 
\begin{align*}
	\Probt{x_1 \leq \tfrac{\sqrt{n}(\theta-\thetahat)}{\sqrt{\theta(1-\theta)}} \leq x_2} = 1-\alpha \Leftrightarrow \Probt{\thetahat + \tfrac{x_1\sqrt{\theta(1-\theta)}}{\sqrt{n}} \leq \theta \leq \thetahat + \tfrac{x_2\sqrt{\theta(1-\theta)}}{\sqrt{n}}} = 1-\alpha.
\end{align*}
Sin embargo, los bordes de este intervalo no son conocidos, pues dependen de $\theta$. Una forma de aproximar el intervalo es reemplazar el parámetro por su EMV. 
\end{example}


\begin{exercise}[Encuesta de elecciones presidenciales] Considere una encuesta que ha consultado a 1000 votantes y su candidato ha recibido 200 votos. Use el resultado del ejemplo anterior para determinar el intervalo de confianza del 95\% de la cantidad de votos que su candidato obtendría en la elección presidencial. 
\end{exercise}

Finalmente, revisaremos el siguiente ejemplo, el cual pretende ejemplificar el concepto de que en solo un experimento, la determinación del $(1-\alpha)$-intervalo de confianza no quiere decir que la probabilidad de que el parámetro esté contenido en él es $(1-\alpha)$\%. 

\begin{example}[Intervalo de confianza para una distribución uniforme] Considere $X_1,X_2\sim\uni{\theta-\tfrac{1}{2},\theta+\tfrac{1}{2}}$ y observe que 
\begin{align*}
	\Probt{\min(X_1,X_2) \leq \theta \leq \max(X_1,X_2)} 
		&= \Probt{ X_1 \leq \theta \leq X_2}  + \Probt{ X_2 \leq \theta \leq X_1} \\
		&= \frac{1}{2}\times \frac{1}{2} + \frac{1}{2}\times\frac{1}{2}\\
		&= \frac{1}{2}
\end{align*}
corresponde al intervalo del 50\%. 

Sin embargo, si observáramos $X_1 = x_1$ y $X_2 = x_2$ tal que $|x_1-x_2|\geq\tfrac{1}{2}$ entonces necesariamente está contenido en el intervalo $(\min(X_1,X_2) , \max(X_1,X_2))$ con probabilidad 1. Esto ilustra la idea de que, en un experimento dado, la probabilidad de que $\theta$ esté en intervalo de confianza del $(1-\alpha)$\% no es necesariamente $(1-\alpha)$\%.
\end{example}

\section{Intervalos de Confianza Bayesianos}
El paradigma bayesiano propone una noción de intervalos de confianza más natural que el enfoque frecuentista, dado que la notación $\mathbb{P}(\theta \in C_x)$ tiene un significado, incluso condicional a $x$.
\begin{definition}
Para un prior $\pi$, un conjunto $C_x$ se dice  $\alpha$-creíble si :
$$
\mathbb{P}^{\pi}(\theta \in C_x |x) \geq 1- \alpha,
$$
para la probabilidad dada por el prior $\pi$. Esta región se dice de Alta Densidad Posterior (HPD por su sigla en inglés) si se puede escribir como:
$$
\left \{\theta: \pi(\theta|x) > k_{\alpha} \right \} \subset C_{x}^{\pi} \subset \left \{ \theta: \pi(\theta|x) \geq  k_{\alpha}\right \} ,
$$
donde $k_{\alpha}$ es la cota más grande tal que: 
$$
\mathbb{P}^{\pi}(\theta \in C_{k}^{\pi}|x) \geq 1- \alpha
$$
\end{definition}
\begin{remark}
    El hecho de considerar regiones HPD viene de que minimizan el volumen entre las regiones $\alpha$-creíbles. 
\end{remark}

\begin{example}
Si $\theta \sim \mathcal{N}(0,\tau^{2})$, la posterior de $\theta$ es una normal $\mathcal{N}(\mu(x),\omega^{-2})$, con $\omega^{2}= \tau^{-2} + \sigma^{-2} $
y $\mu(x)=\dfrac{\tau^{2}x}{\tau^2 + \sigma^2}$. Luego: 
$$
C_{\alpha}^{\pi} =[\mu(x) - k_{\alpha}\omega^{-1},\mu(x)+k_{\alpha}\omega^{-1} ]
$$
con $k_{\alpha}$ el $\alpha /2 $-intil de $\mathcal{N}(0,1)$. En particular, si $\tau \to \infty$, $\pi(\theta)$ converge a la medida de Lebesgue en $\R $ y: 
$$
C_{\alpha}= [x - k_{\alpha}\sigma ,x + k_{\alpha}\sigma],
$$
que corresponde al intervalo de confianza clásico para una normal. 
\end{example}